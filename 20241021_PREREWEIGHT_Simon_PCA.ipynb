{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:14:40.341874: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-21 17:14:40.699937: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from _utils import *\n",
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))  # This prevents crash on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/mnt/home/tudomlumleart/ceph/15_SimonDataset/df20240311_posrate30-50p.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scipy.io.loadmat(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = [dataset['df'][:, i][0][0] for i in range(4)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the missing data\n",
    "dataset_polys = []\n",
    "for sample in dataset_list: \n",
    "    dataset_polys.append(interpolate_polymers(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maps = []\n",
    "for sample in dataset_polys:\n",
    "    dataset_maps.append(calculate_distance_map(sample))\n",
    "    \n",
    "dataset_maps_flat = []\n",
    "label_list = []\n",
    "for i, sample in enumerate(dataset_maps):\n",
    "    curr_data_flat = [x.flatten() for x in sample]\n",
    "    dataset_maps_flat.append(curr_data_flat)\n",
    "    label_list.extend([str(i)] * len(curr_data_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maps_all = np.concatenate(dataset_maps, axis=0)\n",
    "dataset_maps_flat_all = np.concatenate(dataset_maps_flat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16730, 2601)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_maps_flat_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16730"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _reweight import reweight_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/MCMC_results/20241021_RunWeightMCMC_Simon_PCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight_samples(\n",
    "    distance_map_list,\n",
    "    distance_map_flat_list,\n",
    "    sample_labels,\n",
    "    num_microstates,\n",
    "    save_dir,\n",
    "    method='PCA',\n",
    "    slurm_file=None):\n",
    "    # Add docstring \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_probes = distance_map_list.shape[1]\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    if slurm_file is None:\n",
    "        slurm_file = '/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/slurm/2024_RunPythonScript.sh'        \n",
    "    \n",
    "    print('PCA Fitting...')\n",
    "    if method == 'PCA':\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(distance_map_flat_list)\n",
    "        pca_samples = []\n",
    "        unique_labels = np.unique(sample_labels)\n",
    "        for label in unique_labels:\n",
    "            pca_samples.append(pca.transform(distance_map_flat_list[sample_labels == label, :]))\n",
    "            \n",
    "        df_sample_list = []\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            df_sample = pd.DataFrame(pca_samples[i], columns=['PC1', 'PC2'])\n",
    "            df_sample['label'] = label\n",
    "            df_sample_list.append(df_sample)\n",
    "        df_samples = pd.concat(df_sample_list, axis=0)\n",
    "        \n",
    "        min_pc1 = df_samples['PC1'].min()\n",
    "        max_pc1 = df_samples['PC1'].max()\n",
    "        min_pc2 = df_samples['PC2'].min()\n",
    "        max_pc2 = df_samples['PC2'].max()\n",
    "        \n",
    "        num_microstate_per_axis = np.round(np.sqrt(num_microstates), 0).astype(int)\n",
    "        \n",
    "        microstate_distance_maps = generate_microstates(\n",
    "            min_pc1, max_pc1, min_pc2, max_pc2, num_microstate_per_axis, pca)\n",
    "       \n",
    "    print('Calculating likelihood...') \n",
    "    microstate_distance_maps_jnp = jnp.array(microstate_distance_maps)\n",
    "    print(microstate_distance_maps_jnp.shape)\n",
    "    sample_std = []\n",
    "    sample_ll = []\n",
    "    sample_num = []\n",
    "    for label in unique_labels:\n",
    "        curr_condition = jnp.array(distance_map_list[sample_labels == label, :, :])\n",
    "        print(curr_condition.shape)\n",
    "        curr_std = batch_calculate_variances(curr_condition,\n",
    "                                             microstate_distance_maps_jnp,\n",
    "                                             num_probes) ** 0.5\n",
    "        sample_std.append(curr_std)\n",
    "        \n",
    "        curr_ll = []\n",
    "        for y in tqdm(curr_condition):\n",
    "            curr_ll.append(compute_loglikelihood_for_y(\n",
    "                y.flatten(), microstate_distance_maps_jnp, \n",
    "                curr_std, num_probes).tolist()) \n",
    "        \n",
    "        sample_num.append(curr_condition.shape[0])\n",
    "        sample_ll.append(curr_ll)\n",
    "\n",
    "    lpm = [(logprior(x, num_probes)).tolist() for x in microstate_distance_maps]\n",
    "    \n",
    "    # Load stan model \n",
    "    my_model = CmdStanModel(\n",
    "        stan_file='/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/stan/20240715_WeightOptimization.stan',\n",
    "        cpp_options = {\n",
    "            \"STAN_THREADS\": True,\n",
    "        }\n",
    "        )\n",
    "    \n",
    "    print('Saving data...')\n",
    "    for i, label in tqdm(enumerate(unique_labels)):\n",
    "        output_dir = os.path.join(save_dir, label)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        json_filename = os.path.join(output_dir, 'data.json')\n",
    "        stan_output_file = os.path.join(output_dir, 'stan_output')\n",
    "        \n",
    "        data_dict = {\n",
    "            'N': sample_num[i],\n",
    "            'M': num_microstates,\n",
    "            'll_map': sample_ll[i],\n",
    "            'lpm_vec': lpm\n",
    "        }\n",
    "        \n",
    "        json_obj = json.dumps(data_dict, indent=4)\n",
    "        \n",
    "        with open(json_filename, 'w') as f:\n",
    "            f.write(json_obj)\n",
    "            f.close()\n",
    "    \n",
    "    print('Submitting slurm jobs...')       \n",
    "    submit_mcmc_slurm(save_dir, slurm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Fitting...\n",
      "Calculating likelihood...\n",
      "(5625, 2601)\n",
      "(3107, 51, 51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da7b29372564eda9e327f3a21b19d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4574, 51, 51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edc67ebd27f43c7ac3c7749fe384a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4760, 51, 51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cc7618033d42c0bc7c36cbfffa56f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4289, 51, 51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4588207bf6aa4d3494170012611cdd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dd2ac4eaaa4783b18429f18c8e0aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm jobs...\n",
      "Submitting slurm job for 3\n",
      "Submitted batch job 4082521\n",
      "Submitting slurm job for 2\n",
      "Submitted batch job 4082522\n",
      "Submitting slurm job for 1\n",
      "Submitted batch job 4082523\n",
      "Submitting slurm job for 0\n",
      "Submitted batch job 4082525\n"
     ]
    }
   ],
   "source": [
    "reweight_samples(dataset_maps_all,\n",
    "                dataset_maps_flat_all, \n",
    "                 label_list, \n",
    "                 75**2,\n",
    "                 save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu-openmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
