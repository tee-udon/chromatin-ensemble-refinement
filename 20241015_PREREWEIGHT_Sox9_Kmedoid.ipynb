{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 19:13:52.750777: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 19:13:52.792152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from _utils import *\n",
    "from scipy.stats import qmc\n",
    "import kmedoids\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def calculate_conformational_variance_jax(dmap_list, dmap_ref):\n",
    "    \"\"\"\n",
    "    Calculate the conformational variation of a set of distance maps relative to a reference map.\n",
    "\n",
    "    Parameters:\n",
    "    dmap_list (list): A list of 2D numpy arrays representing the distance maps.\n",
    "    dmap_ref (np.ndarray): A 2D numpy array representing the reference distance map.\n",
    "    num_probes (int): The number of probes in the distance maps.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A 2D numpy array containing the variance of the squared Euclidean distances \n",
    "               between each distance map and the reference map.\n",
    "    \"\"\"\n",
    "    # Convert dmap_list to a NumPy array\n",
    "    dmap_list = jnp.array(dmap_list)\n",
    "    \n",
    "    # Calculate the squared Euclidean distance between each distance map and the reference map\n",
    "    diff_list = jnp.sqrt((dmap_list - dmap_ref) ** 2) \n",
    "    \n",
    "    # Calculate the variance along the number of observation/cell dimension\n",
    "    var = jnp.var(diff_list, axis=0)\n",
    "    \n",
    "    return var\n",
    "\n",
    "\n",
    "# Rewrite this in a jax-compatible fashion\n",
    "from functools import partial\n",
    "@partial(jax.jit, static_argnums=(2,)) \n",
    "def batch_calculate_variances(dmap_list, dmap_ref, num_probes):\n",
    "    \"\"\"\n",
    "    Vectorized version that applies calculate_conformational_variance_jax across a batch of distance maps.\n",
    "    \"\"\"\n",
    "    return jax.vmap(lambda dmap: calculate_conformational_variance_jax(dmap_list, jnp.reshape(dmap, [num_probes, num_probes])))(dmap_ref)\n",
    "\n",
    "\n",
    "# Define the main loglikelihood function using JAX\n",
    "def loglikelihood_jax(dmap_flat, ref_dmap_flat, measurement_error, num_probes):\n",
    "    return jnp.sum(_loglikelihood_jax(dmap_flat, ref_dmap_flat, measurement_error, num_probes))\n",
    "\n",
    "\n",
    "# Define the helper function, with JAX-compatible logic\n",
    "def _loglikelihood_jax(dmap_flat, ref_dmap_flat, measurement_error, num_probes):\n",
    "    # Use lax.cond for control flow based on the condition\n",
    "    min_value = jnp.iinfo(jnp.int32).min\n",
    "    \n",
    "    def handle_invalid_reference(ref_dmap_flat):\n",
    "        # Return extremely low probability when ref_dmap_flat contains invalid values\n",
    "        return jnp.array([jnp.float32(min_value), jnp.float32(min_value)])\n",
    "    \n",
    "    def handle_valid_reference(ref_dmap_flat):\n",
    "        # Calculate the difference between distance map and reference \n",
    "        subtraction_map_sq = jnp.square(dmap_flat - ref_dmap_flat).reshape(num_probes, num_probes)\n",
    "\n",
    "        # Only consider the upper triangular part of the distance map\n",
    "        # because the diagonal values do not have variance\n",
    "        triu_indices = jnp.triu_indices(num_probes, k=1)\n",
    "        measurement_error_scaled = 2 * measurement_error[triu_indices]  # both triangles \n",
    "        subtraction_map_sq_scaled = 2 * subtraction_map_sq[triu_indices]  # both triangles\n",
    "        \n",
    "        # Calculate the normalization factor\n",
    "        normalization_factor = -jnp.sum(jnp.log(jnp.sqrt(2 * jnp.pi * measurement_error_scaled**2)))\n",
    "        \n",
    "        # Calculate the Gaussian term \n",
    "        gaussian_term = -jnp.sum(subtraction_map_sq_scaled / (2 * jnp.square(measurement_error_scaled)))\n",
    "        \n",
    "        return jnp.array([normalization_factor, gaussian_term])\n",
    "\n",
    "    # Apply the appropriate logic depending on whether ref_dmap_flat contains negative values\n",
    "    return lax.cond(\n",
    "        jnp.any(ref_dmap_flat <= -1),\n",
    "        handle_invalid_reference,\n",
    "        handle_valid_reference,\n",
    "        ref_dmap_flat\n",
    "    )\n",
    "    \n",
    "def compute_loglikelihood_for_y(y, templates_flatten, measurement_error_esc, num_probes):\n",
    "    return jax.vmap(lambda x, z: loglikelihood_jax(y, x, z, num_probes))(templates_flatten, measurement_error_esc)\n",
    "\n",
    "\n",
    "folder_path = '/mnt/home/tudomlumleart/ceph/05_Sox9Dataset/'\n",
    "    \n",
    "num_monomers = 80\n",
    "\n",
    "# Load polys data and then perform linear interpolation\n",
    "# List all .mat files in the folder and load them\n",
    "cnc_polys = scipy.io.loadmat(folder_path + 'cncPols.mat')['cncPols'][:num_monomers, :, :]\n",
    "esc_polys = scipy.io.loadmat(folder_path + 'escPols.mat')['escPols'][:num_monomers, :, :]\n",
    "\n",
    "esc_polys_interp = interpolate_polymers(esc_polys)\n",
    "cnc_polys_interp = interpolate_polymers(cnc_polys)\n",
    "\n",
    "def calculate_distance_map(polys):\n",
    "    # Extract the dimensions of the input array\n",
    "    num_probes, num_coords, num_cells = polys.shape\n",
    "    \n",
    "    # Initialize an array of the same shape to hold the interpolated values\n",
    "    new_maps = np.zeros((num_cells, num_probes, num_probes))\n",
    "    \n",
    "    # Iterate over each cell\n",
    "    for c in range(num_cells):\n",
    "        # Extract the data for the current cell\n",
    "        curr_cells = polys[:, :, c]\n",
    "        \n",
    "        # Skip cells with all missing values\n",
    "        if np.all(np.isnan(curr_cells)):\n",
    "            continue  # This leaves a matrix of zeros in the output array\n",
    "        \n",
    "        # Calculate the pairwise Euclidean distance between each pair of probes\n",
    "        dmap = squareform(pdist(curr_cells))\n",
    "        \n",
    "        # Assign the distance map to the corresponding position in the output array\n",
    "        new_maps[c, :, :] = dmap\n",
    "    \n",
    "    # Return the array with interpolated values\n",
    "    return new_maps\n",
    "\n",
    "esc_maps_interp = calculate_distance_map(esc_polys_interp)\n",
    "cnc_maps_interp = calculate_distance_map(cnc_polys_interp)\n",
    "esc_maps_interp_flat = np.array([x.flatten() for x in esc_maps_interp])\n",
    "cnc_maps_interp_flat = np.array([x.flatten() for x in cnc_maps_interp])\n",
    "all_maps_interp = np.concatenate((esc_maps_interp, cnc_maps_interp), axis=0)\n",
    "all_maps_interp_flat = np.concatenate((esc_maps_interp_flat, cnc_maps_interp_flat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diss = euclidean_distances(all_maps_interp_flat)\n",
    "kmin_list = [75, 100, 150, 200, 300]\n",
    "\n",
    "mds_list = []\n",
    "for kmin in kmin_list:\n",
    "    md = kmedoids.fasterpam(diss, kmin, max_iter=100, init='random', random_state=None, n_cpu=-1)\n",
    "    mds_list.append(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_microstates_list = []\n",
    "for md in mds_list:\n",
    "    medoids_idx = md.medoids\n",
    "    medoids_microstates = all_maps_interp_flat[medoids_idx]\n",
    "    mds_microstates_list.append(medoids_microstates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 20:27:27.224761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))  # This prevents crash on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_mcmc_slurm(mcmc_common_dir, slurm_file):\n",
    "    # List all the directories in the MCMC common directory\n",
    "    # Only return directories that contain data.json\n",
    "    dirs = []\n",
    "\n",
    "    # List all items in the current directory\n",
    "    for item in os.listdir(mcmc_common_dir):\n",
    "        # Get the full path of the item\n",
    "        full_path = os.path.join(mcmc_common_dir, item)\n",
    "        \n",
    "        # Check if the item is a directory\n",
    "        # And if the directory contains data.json\n",
    "        # Check if 'data.json' exists in the directory\n",
    "        file_path = os.path.join(full_path, 'data.json')\n",
    "        if os.path.isfile(file_path):\n",
    "            dirs.append(full_path)\n",
    "            \n",
    "    # Submit a slurm job for each directory\n",
    "    for dir in dirs:\n",
    "        # Get the name of the directory\n",
    "        \n",
    "        dir_name = os.path.basename(dir)\n",
    "        print(f\"Submitting slurm job for {dir_name}\")\n",
    "        \n",
    "        run_mcmc_py = '/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/_run_mcmc.py'\n",
    "        \n",
    "        # Submit a slurm job\n",
    "        cmd = f'sbatch {slurm_file} {run_mcmc_py} {dir}'\n",
    "        \n",
    "        # Run the command\n",
    "        os.system(cmd)\n",
    "\n",
    "slurm_file = '/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/slurm/2024_RunPythonScript.sh'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c1a06c634c475b9db9e94cd14e0935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 20:27:40.457854: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4394b2e1e2bf46379bc357cb47df7bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cc60141147431e9a088f841984c306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 64\n",
      "Number of threads per chain: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd53afd757645a3ad7e993e8468dd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm job for ESC\n",
      "Submitted batch job 4069596\n",
      "Submitting slurm job for CNC\n",
      "Submitted batch job 4069597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9d4c6eef044f92a6e9c6c2e5616c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b538bb673840ad9a9f72f2f3b1835e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 64\n",
      "Number of threads per chain: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc587785acb47e580aceef4100d5f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm job for ESC\n",
      "Submitted batch job 4069599\n",
      "Submitting slurm job for CNC\n",
      "Submitted batch job 4069600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e3687559f24852a7eb58d6b4afa4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d580d28961324915a423f6f6f1e3d78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 64\n",
      "Number of threads per chain: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bbec72eba34057a26d7d49060f9c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm job for ESC\n",
      "Submitted batch job 4069603\n",
      "Submitting slurm job for CNC\n",
      "Submitted batch job 4069604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0190aa705c4e37974580ff37090b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdf3b8638dd4d6bafbd156601a9652f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 64\n",
      "Number of threads per chain: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6248ff79a99640a3ba41002188634964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm job for ESC\n",
      "Submitted batch job 4069613\n",
      "Submitting slurm job for CNC\n",
      "Submitted batch job 4069614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef5d67a5a1747eb831027da03fd08a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d28c852c51248de85af3bab38473131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 64\n",
      "Number of threads per chain: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de921c055614d3a845285fdb19c7195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting slurm job for ESC\n",
      "Submitted batch job 4069623\n",
      "Submitting slurm job for CNC\n",
      "Submitted batch job 4069624\n"
     ]
    }
   ],
   "source": [
    "for i, kmin in tqdm(enumerate(kmin_list)):\n",
    "    num_microstates = kmin\n",
    "    microstates_maps_jax = jnp.array(mds_microstates_list[i])\n",
    "    esc_std = batch_calculate_variances(jnp.array(esc_maps_interp), microstates_maps_jax, num_monomers)**0.5\n",
    "    cnc_std = batch_calculate_variances(jnp.array(cnc_maps_interp), microstates_maps_jax, num_monomers)**0.5\n",
    "\n",
    "    lpm = [(logprior(x, num_monomers)).tolist() for x in microstates_maps_jax]\n",
    "    \n",
    "    esc_ll = [compute_loglikelihood_for_y(y, microstates_maps_jax, esc_std, num_monomers) for y in tqdm(esc_maps_interp_flat)]\n",
    "    cnc_ll = [compute_loglikelihood_for_y(y, microstates_maps_jax, cnc_std, num_monomers) for y in tqdm(cnc_maps_interp_flat)]\n",
    "\n",
    "    esc_ll = [x.tolist() for x in esc_ll]\n",
    "    cnc_ll = [x.tolist() for x in cnc_ll]\n",
    "\n",
    "    N_esc = esc_maps_interp_flat.shape[0]\n",
    "    N_cnc = cnc_maps_interp_flat.shape[0]\n",
    "\n",
    "    M = num_microstates\n",
    "\n",
    "    my_model = CmdStanModel(\n",
    "        stan_file='/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/stan/20240715_WeightOptimization.stan',\n",
    "        cpp_options = {\n",
    "            \"STAN_THREADS\": True,\n",
    "        }\n",
    "        )\n",
    "\n",
    "    n_cores = multiprocessing.cpu_count()\n",
    "    print(f\"Number of CPU cores: {n_cores}\")\n",
    "    parallel_chains = 4\n",
    "    threads_per_chain = int(n_cores / parallel_chains)\n",
    "    print(f\"Number of threads per chain: {threads_per_chain}\")\n",
    "    \n",
    "    save_dir = f'/mnt/home/tudomlumleart/ceph/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/MCMC_results/20241014_RunWeightMCMC_Sox9_Kmedoid_{kmin}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    # Save microstates and md in pickle file\n",
    "    with open(os.path.join(save_dir, 'param.pkl'), 'wb') as f:\n",
    "        param_pickle = {\n",
    "            'microstates': mds_microstates_list[i],\n",
    "            'medoid_model': mds_list[i]\n",
    "        }\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(param_pickle, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    conditions = [\n",
    "        'ESC', 'CNC'\n",
    "    ]\n",
    "\n",
    "    for condition in tqdm(conditions):\n",
    "        output_dir = os.path.join(save_dir, condition)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        json_filename = os.path.join(output_dir, 'data.json')\n",
    "        stan_putput_file = os.path.join(output_dir, 'stan_output')\n",
    "        \n",
    "        if condition == 'ESC':\n",
    "            data_dict = {\n",
    "                'N': N_esc,\n",
    "                'M': M,\n",
    "                'll_map': esc_ll,\n",
    "                'lpm_vec': lpm,\n",
    "            }\n",
    "        \n",
    "        elif condition == 'CNC':\n",
    "            data_dict = {\n",
    "                'N': N_cnc,\n",
    "                'M': M,\n",
    "                'll_map': cnc_ll,\n",
    "                'lpm_vec': lpm,\n",
    "            }\n",
    "            \n",
    "        json_obj = json.dumps(data_dict, indent=4)\n",
    "        \n",
    "        with open(json_filename, 'w') as json_file:\n",
    "            json_file.write(json_obj)\n",
    "            json_file.close()\n",
    "            \n",
    "    submit_mcmc_slurm(save_dir, slurm_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu-openmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
