{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_debug_nans\", True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "num_monomers = 20 \n",
    "mean_bond_length = 1\n",
    "std_bond_length = 20\n",
    "gaussian_noise_std = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_posterior_parallelize(templates_flatten, observations_flatten, template_weights):\n",
    "    \"\"\"\n",
    "    \"\"\" \n",
    "    templates_flatten = jnp.array(templates_flatten)\n",
    "    observations_flatten = jnp.array(observations_flatten)\n",
    "    \n",
    "    template_weights = jnp.array(template_weights)\n",
    "    \n",
    "    weight_prior = 1/len(template_weights) \n",
    "    \n",
    "    # Generate grid index combination\n",
    "    template_info_indices = jnp.arange(len(templates_flatten))\n",
    "    observation_info_indices = jnp.arange(len(observations_flatten))\n",
    "    t_ind, o_ind = jnp.meshgrid(template_info_indices, observation_info_indices)\n",
    "    \n",
    "    total_posterior = 0\n",
    "    \n",
    "    t_ind = t_ind.flatten()\n",
    "    o_ind = o_ind.flatten()\n",
    "        \n",
    "    \n",
    "    # jax.debug.print(\"Weights at current iteration: {y}\", y=template_weights)\n",
    "    def calculate_rhs(t_ind, o_ind):\n",
    "        val = 0 \n",
    "        o = observations_flatten[o_ind]\n",
    "        t = templates_flatten[t_ind]\n",
    "        alpha = template_weights[t_ind]\n",
    "        \n",
    "        ll = loglikelihood(o, t, measurement_error, num_probes)\n",
    "        lp = logprior(t, num_probes)\n",
    "        # jax.debug.print(\"{x}, {y}\", x=t, y=lp)\n",
    "        lw = jnp.log(jnp.abs(alpha)) + 1e-32\n",
    "        lwp = jnp.log(weight_prior)\n",
    "        \n",
    "        rhs = jnp.array([ll, lp, lw, lwp])\n",
    "        \n",
    "        # mantissa = jnp.log10(jnp.abs(rhs)) - jnp.floor(jnp.log10(jnp.abs(rhs)))\n",
    "        # Use absolute value to not care because only the value matters ?\n",
    "        # jax.debug.print(\"{z}, {x}\", z=alpha, x = log_scale_rhs_max)\n",
    "        # jax.debug.print(\"{y}, {z}, {x}, {a}\", y= t_ind, z=o_ind, x = log_scale_rhs_max, a=log_scale_rhs)\n",
    "        # mantissa = jnp.sign(rhs) * mantissa\n",
    "\n",
    "        \n",
    "        # val = jnp.sum(mantissa)\n",
    "        \n",
    "        val = jnp.sum(rhs)\n",
    "        \n",
    "        return val \n",
    "    \n",
    "    def calculate_posterior(i):\n",
    "        # jax.debug.print(\"{x}\", x=curr_obs_list.shape)\n",
    "        # jax.debug.print(\"{y} {x}\", y=i, x=jnp.sum(jnp.isnan(jnp.where(o_ind == i, curr_obs_list, -jnp.inf))))\n",
    "        # jax.debug.print(\"{z} {x} {y}\", z=i, x=jnp.where(o_ind == i, curr_obs_list, -jnp.inf), y=jscipy.special.logsumexp(jnp.where(o_ind == i, curr_obs_list, -jnp.inf)))\n",
    "        \n",
    "        return jscipy.special.logsumexp(jnp.where(o_ind == i, curr_obs_list, -jnp.inf))\n",
    "    \n",
    "    curr_obs_list = jnp.array(jax.vmap(calculate_rhs)(t_ind, o_ind))\n",
    "    \n",
    "    \n",
    "    \n",
    "    total_posterior = jnp.sum(jax.vmap(calculate_posterior)(jnp.arange(len(observations_flatten))))\n",
    "    # print(total_posterior)\n",
    "\n",
    "    return total_posterior\n",
    "\n",
    "def structure_neg_objective_parallelize(templates):\n",
    "    \"\"\"\n",
    "    \"\"\" \n",
    "    template_weights = num_observation_list\n",
    "    # jax.debug.print(\"{x}\", x=-generate_posterior_parallelize(templates, observations_flatten, template_weights))\n",
    "    \n",
    "    return -generate_posterior_parallelize(templates, observations_flatten, template_weights)\n",
    "\n",
    "def prediction_error(predicted_flat_dmaps, true_flat_dmaps):\n",
    "    err = cdist(predicted_flat_dmaps, true_flat_dmaps)/num_monomers**2\n",
    "    r, c = linear_sum_assignment(err)\n",
    "    return err[r, c].mean()\n",
    "\n",
    "def generate_distance_map(chain):\n",
    "    # Step 1: Compute the squared differences\n",
    "    diff = chain[:, jnp.newaxis, :] - chain[jnp.newaxis, :, :]\n",
    "    squared_diff = jnp.square(diff)\n",
    "\n",
    "    # Step 2: Sum over the feature dimension to get squared distances\n",
    "    squared_distances = jnp.sum(squared_diff, axis=-1)\n",
    "\n",
    "    # Step 3: Take the square root to get the Euclidean distances\n",
    "    distances = jnp.sqrt(squared_distances)\n",
    "    return distances\n",
    "\n",
    "def pdist2(vec1, vec2):\n",
    "    vec1 = jnp.array(vec1)\n",
    "    vec2 = jnp.array(vec2)\n",
    "    \n",
    "    diff = vec1[:, jnp.newaxis, :] - vec2[jnp.newaxis, :, :]\n",
    "    squared_diff = jnp.square(diff)\n",
    "    \n",
    "    squared_distances = jnp.sum(squared_diff, axis=-1)\n",
    "    \n",
    "    distance_matrix = jnp.sqrt(squared_distances)\n",
    "    return distance_matrix\n",
    "\n",
    "def generate_gaussian_chain_jax(num_monomers: int, \n",
    "                            mean_bond_length: float, \n",
    "                            std_bond_length: float,\n",
    "                            random_key: int = None):\n",
    "    \"\"\"Generate a Gaussian chain polymer \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_monomers\n",
    "    mean_bond_length\n",
    "    std_bond_length\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    np.array \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    \"\"\" \n",
    "    # Generate PRNG key\n",
    "    # Create an initial PRNG key\n",
    "    if random_key is None:\n",
    "        random_key = jax.random.PRNGKey(42)\n",
    "    \n",
    "    # Generate steps: each step is a 3D vector \n",
    "    steps = mean_bond_length + std_bond_length * jax.random.normal(random_key, shape=(num_monomers, 3))\n",
    "\n",
    "    # Compute positions by cumulative sum of steps\n",
    "    positions = jnp.cumsum(steps, axis=0)\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def generate_observations_jax(polymer_chain, num_observations, gaussian_noise_std, random_key):\n",
    "    \"\"\" Given a template polymer chain, generate num_observations polymer chains by adding \n",
    "    some gaussian noise to the polymer chain\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    polymer_chain\n",
    "    num_observations\n",
    "    gaussian_noise_std\n",
    "    random_key\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \"\"\"\n",
    "    num_monomers = polymer_chain.shape[0] \n",
    "    \n",
    "    \n",
    "    # Parameters for Gaussian noise \n",
    "    mean = 0 \n",
    "    std = gaussian_noise_std\n",
    "    \n",
    "    # Generate noise profile\n",
    "    # jax.debug.print('{x}', x=jax.random.normal(key=random_key, shape=(num_observations, num_monomers, 3)))\n",
    "    noise = mean + std * jax.random.normal(key=random_key, shape=(num_observations, num_monomers, 3))\n",
    "        \n",
    "    # Add noise to the original data\n",
    "    noisy_data = polymer_chain + noise \n",
    "    \n",
    "    return noisy_data\n",
    "\n",
    "def simulation(k):\n",
    "    num_models = num_templates\n",
    "    init_model = [generate_gaussian_chain_jax(num_monomers, mean_bond_length, std_bond_length, k) for m in range(num_models)]\n",
    "    init_model = [jnp.ravel(generate_distance_map(m)) for m in init_model]\n",
    "    \n",
    "    pg = ProjectedGradient(fun=structure_neg_objective_parallelize, projection=projection_non_negative, implicit_diff=True, verbose=False)\n",
    "    pg_sol = pg.run(init_model)\n",
    "    \n",
    "    dmaps_flat = [generate_flatten_distance_map(x) for x in template_chain_list]\n",
    "    error_matrix = pdist2(pg_sol.params, dmaps_flat)\n",
    "    return error_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,  10., 100.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf1f6e5e0c24b73b5b21f980fd2cb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 14:45:00.747420: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 942.50GiB (rounded to 1012004184320)requested by op \n",
      "2024-06-12 14:45:00.747601: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:497] *___________________________________________________________________________________________________\n",
      "2024-06-12 14:45:00.748658: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2410] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1012004184184 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:   30.52MiB\n",
      "              constant allocation:   22.86MiB\n",
      "        maybe_live_out allocation:   30.52MiB\n",
      "     preallocated temp allocation:  942.50GiB\n",
      "  preallocated temp fragmentation:        96B (0.00%)\n",
      "                 total allocation:  942.58GiB\n",
      "              total fragmentation:   53.41MiB (0.01%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 929.09GiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,4994,499400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 13.21GiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/transpose(jvp(vmap(jit(_where))))/reduce_sum[axes=(1,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,71,499400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 190.51MiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jvp(vmap(jit(logprior)))/jit(logprior_)/reduce_sum[axes=(2,)]\" source_file=\"/mnt/home/tudomlumleart/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/functions.py\" source_line=387\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,499400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 15.26MiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/concatenate[dimension=1]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=4\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 7.62MiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f32[4994,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 7.62MiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f32[4994,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 7.62MiB\n",
      "\t\tXLA Label: constant\n",
      "\t\tShape: f32[4994,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 1.90MiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_sum[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n",
      "\t\tXLA Label: reduce\n",
      "\t\tShape: f32[100,4994]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 1.90MiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,4994]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 156.2KiB\n",
      "\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[100,400]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1012004184184 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   30.52MiB\n              constant allocation:   22.86MiB\n        maybe_live_out allocation:   30.52MiB\n     preallocated temp allocation:  942.50GiB\n  preallocated temp fragmentation:        96B (0.00%)\n                 total allocation:  942.58GiB\n              total fragmentation:   53.41MiB (0.01%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 929.09GiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,4994,499400]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 13.21GiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/transpose(jvp(vmap(jit(_where))))/reduce_sum[axes=(1,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,71,499400]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 190.51MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jvp(vmap(jit(logprior)))/jit(logprior_)/reduce_sum[axes=(2,)]\" source_file=\"/mnt/home/tudomlumleart/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/functions.py\" source_line=387\n\t\tXLA Label: fusion\n\t\tShape: f32[100,499400]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 15.26MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/concatenate[dimension=1]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=4\n\t\tXLA Label: fusion\n\t\tShape: f32[100,100,400]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 1.90MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_sum[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: reduce\n\t\tShape: f32[100,4994]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 1.90MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,4994]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m observation_class_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([[i \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(j)] \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(num_observation_list)])\n\u001b[1;32m     23\u001b[0m observations_flatten \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray([generate_flatten_distance_map(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m observation_list])\n\u001b[0;32m---> 24\u001b[0m error_matrices\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     26\u001b[0m loop_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 171\u001b[0m, in \u001b[0;36msimulation\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m    168\u001b[0m init_model \u001b[38;5;241m=\u001b[39m [jnp\u001b[38;5;241m.\u001b[39mravel(generate_distance_map(m)) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m init_model]\n\u001b[1;32m    170\u001b[0m pg \u001b[38;5;241m=\u001b[39m ProjectedGradient(fun\u001b[38;5;241m=\u001b[39mstructure_neg_objective_parallelize, projection\u001b[38;5;241m=\u001b[39mprojection_non_negative, implicit_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 171\u001b[0m pg_sol \u001b[38;5;241m=\u001b[39m \u001b[43mpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m dmaps_flat \u001b[38;5;241m=\u001b[39m [generate_flatten_distance_map(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m template_chain_list]\n\u001b[1;32m    174\u001b[0m error_matrix \u001b[38;5;241m=\u001b[39m pdist2(pg_sol\u001b[38;5;241m.\u001b[39mparams, dmaps_flat)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jaxopt/_src/projected_gradient.py:137\u001b[0m, in \u001b[0;36mProjectedGradient.run\u001b[0;34m(self, init_params, hyperparams_proj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m         init_params: Any,\n\u001b[1;32m    134\u001b[0m         hyperparams_proj: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m base\u001b[38;5;241m.\u001b[39mOptStep:\n\u001b[0;32m--> 137\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparams_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jaxopt/_src/base.py:359\u001b[0m, in \u001b[0;36mIterativeSolver.run\u001b[0;34m(self, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m   decorator \u001b[38;5;241m=\u001b[39m idf\u001b[38;5;241m.\u001b[39mcustom_root(\n\u001b[1;32m    353\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimality_fun,\n\u001b[1;32m    354\u001b[0m       has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m       solve\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimplicit_diff_solve,\n\u001b[1;32m    356\u001b[0m       reference_signature\u001b[38;5;241m=\u001b[39mreference_signature)\n\u001b[1;32m    357\u001b[0m   run \u001b[38;5;241m=\u001b[39m decorator(run)\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jaxopt/_src/implicit_diff.py:251\u001b[0m, in \u001b[0;36m_custom_root.<locals>.wrapped_solver_fun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m _signature_bind(solver_fun_signature, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    250\u001b[0m keys, vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys()), \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_custom_vjp_solver_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jaxopt/_src/implicit_diff.py:207\u001b[0m, in \u001b[0;36m_custom_root.<locals>.make_custom_vjp_solver_fun.<locals>.solver_fun_flat\u001b[0;34m(*flat_args)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_vjp\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolver_fun_flat\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_args):\n\u001b[1;32m    206\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m _extract_kwargs(kwarg_keys, flat_args)\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolver_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jaxopt/_src/base.py:321\u001b[0m, in \u001b[0;36mIterativeSolver._run\u001b[0;34m(self, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# We unroll the very first iteration. This allows `init_val` and `body_fun`\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# below to have the same output type, which is a requirement of\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# lax.while_loop and lax.scan.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# of a `lax.cond` for now in order to avoid staging the initial\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# update and the run loop. They might not be staging compatible.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m zero_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_zero_step(init_params, state)\n\u001b[0;32m--> 321\u001b[0m opt_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m init_val \u001b[38;5;241m=\u001b[39m (opt_step, (args, kwargs))\n\u001b[1;32m    324\u001b[0m unroll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unroll_option()\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/gpkc8q6zjnp3n3h3w9hbmbj6gjbxs85w-python-3.10.10-view/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2108\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   2106\u001b[0m   out_bufs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_tokens(input_bufs)\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2108\u001b[0m   out_bufs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded_on_local_devices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   2111\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m bufs \u001b[38;5;129;01min\u001b[39;00m out_bufs:\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1012004184184 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   30.52MiB\n              constant allocation:   22.86MiB\n        maybe_live_out allocation:   30.52MiB\n     preallocated temp allocation:  942.50GiB\n  preallocated temp fragmentation:        96B (0.00%)\n                 total allocation:  942.58GiB\n              total fragmentation:   53.41MiB (0.01%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 929.09GiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,4994,499400]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 13.21GiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/transpose(jvp(vmap(jit(_where))))/reduce_sum[axes=(1,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,71,499400]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 190.51MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jvp(vmap(jit(logprior)))/jit(logprior_)/reduce_sum[axes=(2,)]\" source_file=\"/mnt/home/tudomlumleart/01_ChromatinEnsembleRefinement/chromatin-ensemble-refinement/scripts/functions.py\" source_line=387\n\t\tXLA Label: fusion\n\t\tShape: f32[100,499400]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 15.26MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/concatenate[dimension=1]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=4\n\t\tXLA Label: fusion\n\t\tShape: f32[100,100,400]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 7.62MiB\n\t\tXLA Label: constant\n\t\tShape: f32[4994,400]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 1.90MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_sum[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: reduce\n\t\tShape: f32[100,4994]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 1.90MiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/reduce_max[axes=(2,)]\" source_file=\"/tmp/ipykernel_1396886/3433170373.py\" source_line=55\n\t\tXLA Label: fusion\n\t\tShape: f32[100,4994]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 156.2KiB\n\t\tOperator: op_name=\"jit(update)/jit(main)/jit(<unnamed wrapped function>)/while[cond_nconsts=204 body_nconsts=201]\" source_file=\"/mnt/home/tudomlumleart/.local/lib/python3.10/site-packages/jaxopt/_src/loop.py\" source_line=60\n\t\tXLA Label: fusion\n\t\tShape: f32[100,400]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "# Change the number of templates\n",
    "error_matrices = []\n",
    "times = []\n",
    "\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "\n",
    "measurement_error = gaussian_noise_std\n",
    "num_probes = num_monomers\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "keys = jax.random.split(key, num_iters)\n",
    "for x in tqdm(np.logspace(0, 2, 3)):\n",
    "    start_time = time.time()\n",
    "    num_templates = int(x)\n",
    "    template_chain_list = [generate_gaussian_chain(num_monomers, mean_bond_length, std_bond_length) for i in range(num_templates)]\n",
    "    max_observation_number = 100\n",
    "    num_observation_list = np.random.randint(1, high=max_observation_number, size=num_templates) \n",
    "    observation_list = [generate_observations(c, n, gaussian_noise_std) for c, n in zip(template_chain_list, num_observation_list)]\n",
    "    observation_list = np.concatenate([*observation_list])\n",
    "    observation_class_list = np.concatenate([[i for _ in range(j)] for i, j in enumerate(num_observation_list)])\n",
    "    observations_flatten = jnp.array([generate_flatten_distance_map(t) for t in observation_list])\n",
    "    error_matrices.append(jax.vmap(simulation, in_axes=0)(keys))\n",
    "    end_time = time.time()\n",
    "    loop_time = end_time - start_time\n",
    "    times.append(loop_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.lib.xla_bridge:Remote TPU is not linked into jax; skipping remote TPU.\n",
      "INFO:jax._src.lib.xla_bridge:Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.lib.xla_bridge:Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter Host CUDA\n",
      "INFO:jax._src.lib.xla_bridge:Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "INFO:jax._src.lib.xla_bridge:Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141dbfb9123440cb840c79a6fed9e3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 14:33:05.160516: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  reduce.31 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-06-12 14:33:10.979127: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6.818691637s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  reduce.31 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-06-12 14:33:12.979990: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  reduce.49 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-06-12 14:33:17.910583: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6.930615077s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  reduce.49 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-06-12 14:33:21.911086: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  reduce.87 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-06-12 14:33:24.770299: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6.859274281s\n",
      "Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  reduce.87 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    }
   ],
   "source": [
    "# Change the number of observations\n",
    "\n",
    "error_matrices = []\n",
    "times = []\n",
    "\n",
    "num_templates = 10\n",
    "num_iters = 100\n",
    "\n",
    "template_chain_list = [generate_gaussian_chain(num_monomers, mean_bond_length, std_bond_length) for i in range(num_templates)]\n",
    "\n",
    "measurement_error = gaussian_noise_std\n",
    "num_probes = num_monomers\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "keys = jax.random.split(key, num_iters)\n",
    "for x in tqdm(jnp.logspace(0, 3, 4)):\n",
    "    start_time = time.time()\n",
    "    max_observation_number = x+1\n",
    "    num_observation_list = np.random.randint(1, high=max_observation_number, size=num_templates) \n",
    "    observation_list = [generate_observations(c, n, gaussian_noise_std) for c, n in zip(template_chain_list, num_observation_list)]\n",
    "    observation_list = np.concatenate([*observation_list])\n",
    "    observation_class_list = np.concatenate([[i for _ in range(j)] for i, j in enumerate(num_observation_list)])\n",
    "    observations_flatten = jnp.array([generate_flatten_distance_map(t) for t in observation_list])\n",
    "    error_matrices.append(jax.vmap(simulation, in_axes=0)(keys))\n",
    "    end_time = time.time()\n",
    "    loop_time = end_time - start_time\n",
    "    times.append(loop_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908edb4d3f9048cf9887d49fe1f0d474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_error_matrices = []\n",
    "for sample in tqdm(error_matrices):\n",
    "    err_list = []\n",
    "    for s in sample:\n",
    "        err = s/(num_monomers ** 2)\n",
    "        r, c = linear_sum_assignment(err)\n",
    "        err_list.append(float(err[r, c].mean()))\n",
    "    norm_error_matrices.append(err_list)\n",
    "    \n",
    "norm_error_matrices = np.array(norm_error_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmaps_flat = np.array([generate_flatten_distance_map(x) for x in template_chain_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate bootstrap samples\n",
    "def bootstrap(data, n_bootstrap):\n",
    "    n = len(data)\n",
    "    bootstrap_samples = np.random.choice(data, size=(n_bootstrap, n), replace=True)\n",
    "    return bootstrap_samples\n",
    "\n",
    "# Function to calculate the bootstrap mean\n",
    "def bootstrap_mean(data, n_bootstrap):\n",
    "    samples = bootstrap(data, n_bootstrap)\n",
    "    return np.mean(samples, axis=1)\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstrap = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_CI_list = []\n",
    "\n",
    "for x in norm_error_matrices:\n",
    "    # Calculate bootstrap means\n",
    "    bootstrap_means = bootstrap_mean(x, n_bootstrap)\n",
    "\n",
    "    # Calculate the 95% confidence interval\n",
    "    lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "    upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "    confidence_interval = (upper_bound-x.mean(), x.mean()-lower_bound)\n",
    "    \n",
    "    bootstrap_CI_list.append(confidence_interval)\n",
    "    \n",
    "bootstrap_CI_list = np.array(bootstrap_CI_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05578934, 0.03983368, 0.03994852, 0.04458186],\n",
       "       [0.05131484, 0.03748704, 0.03942414, 0.04198895]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bootstrap_CI_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = np.mean(dmaps_flat, axis=0)\n",
    "max_error = np.mean(np.sqrt(np.sum((centroid - dmaps_flat)**2, axis=-1)))/num_monomers**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6283751095536723"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31341967, 1.21064688, 1.1760643 , 1.21422998])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_error_matrices.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x154af1895ed0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(jnp.logspace(0, 3, 4), norm_error_matrices.mean(axis=1), yerr=bootstrap_CI_list, ecolor='red')\n",
    "plt.axhline(max_error, color='black', label='max error')\n",
    "plt.ylim([0, 2])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Maximum number of observations per template')\n",
    "plt.ylabel('Assignment error')\n",
    "plt.title('Number of templates = 10')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu-openmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
